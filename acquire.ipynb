{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using the code from the lesson as a guide, create a dataframe named items that has all of the data for items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_data():\n",
    "    '''\n",
    "    Create a dataframe named items that has all of the data for items.\n",
    "    '''\n",
    "    base_url = 'https://python.zach.lol'    \n",
    "    response = requests.get('https://python.zach.lol/api/v1/items')\n",
    "    data = response.json()\n",
    "    items_df = pd.DataFrame(data['payload']['items'])\n",
    "    \n",
    "    if os.path.isfile('items_df.csv'):\n",
    "        items_df = pd.read_csv('items_df.csv', index_col = 0)\n",
    "    else:\n",
    "        for x in range(0, data['payload']['max_page']):\n",
    "            response = requests.get(base_url + data['payload']['next_page'])\n",
    "            data = response.json()\n",
    "            items_df = pd.concat([df, pd.DataFrame(data['payload']['items'])], ignore_index = True)\n",
    "            if data['payload']['next_page'] == None:\n",
    "                return items_df\n",
    "        items_df = items_df.reset_index()\n",
    "        \n",
    "    return items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Do the same thing, but for stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_data():\n",
    "    '''\n",
    "    Create a dataframe named store that has all of the data for store.\n",
    "    '''\n",
    "    \n",
    "    base_url = 'https://python.zach.lol'\n",
    "    response = requests.get('https://python.zach.lol/api/v1/stores')\n",
    "    data = response.json()\n",
    "    store_df = pd.DataFrame(data['payload']['stores'])\n",
    "    \n",
    "    if os.path.isfile('stores_df.csv'):\n",
    "        store_df = pd.read_csv('stores_df.csv', index_col = 0)\n",
    "    else:\n",
    "        if data['payload']['next_page'] == None:\n",
    "            return store_df\n",
    "        else:\n",
    "            for x in range(0, data['payload']['max_page']):\n",
    "                response = requests.get(base_url + data['payload']['next_page'])\n",
    "                data = response.json()\n",
    "                store_df = pd.concat([store_df, pd.DataFrame(data['payload']['stores'])], ignore_index = True)\n",
    "            return store_df\n",
    "        store_df = store_df.reset_index()\n",
    "    return store_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract the data for sales. There are a lot of pages of data here, so your code will need to be a little more complex. Your code should continue fetching data from the next page until all of the data is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales_data():\n",
    "    \n",
    "    base_url = 'https://python.zach.lol'\n",
    "    response = requests.get('https://python.zach.lol/api/v1/sales')\n",
    "    data = response.json()\n",
    "    data.keys()\n",
    "    print('max_page: %s' % data['payload']['max_page'])\n",
    "    print('next_page: %s' % data['payload']['next_page'])\n",
    "    \n",
    "    sales_df = pd.DataFrame(data['payload']['sales'])\n",
    "    \n",
    "    \n",
    "    if os.path.isfile('sales_df.csv'):\n",
    "        df = pd.read_csv('sales_df.csv', index_col = 0)\n",
    "    else:\n",
    "        while data['payload']['next_page'] != \"None\":\n",
    "            response = requests.get(base_url + data['payload']['next_page'])\n",
    "            data = response.json()\n",
    "            print('max_page: %s' % data['payload']['max_page'])\n",
    "            print('next_page: %s' % data['payload']['next_page'])\n",
    "\n",
    "            sales_df = pd.concat([sales_df, pd.DataFrame(data['payload']['sales'])])\n",
    "\n",
    "            if data['payload']['next_page'] == None:\n",
    "                break\n",
    "\n",
    "        sales_df = sales_df.reset_index()\n",
    "    print('full_shape', sales_df.shape)\n",
    "    return sales_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Save the data in your files to local csv files so that it will be faster to access in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Combine the data from your three separate dataframes into one large dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data():\n",
    "    '''\n",
    "    Combine items, store, and sales dataframes.\n",
    "    '''\n",
    "    \n",
    "    base_url = 'https://python.zach.lol'\n",
    "    \n",
    "    \n",
    "    if os.path.isfile('items_df.csv'):\n",
    "        item_list = pd.read_csv('items_df.csv', index_col = 0)\n",
    "    else:\n",
    "        item_list = get_items_data()\n",
    "    print(item_list.shape)\n",
    "\n",
    "    if os.path.isfile('stores_df.csv'):\n",
    "        store_list = pd.read_csv('stores_df.csv', index_col=0)\n",
    "    else:\n",
    "        store_list = get_stores_list()\n",
    "    print(store_list.shape)\n",
    "\n",
    "    if os.path.isfile('sales_df.csv'):\n",
    "        sales_list = pd.read_csv('stores_df.csv', index_col=0)\n",
    "    else:\n",
    "        sales_list = get_sales_data()\n",
    "    print(sales_list.shape)\n",
    "    \n",
    "    # Rename columns:\n",
    "    store_list.rename(columns = {'store_id': 'store'}, inplace = True)\n",
    "    print('renamed columns')\n",
    "    \n",
    "    # Merge the three dataframes:\n",
    "    left_merge = pd.merge(sales_list, item_list, how = 'left', on = 'item')\n",
    "    all_df = pd.merge(left_merge, store_list, how = 'left', on = 'store')\n",
    "    \n",
    "    all_df.to_csv('store_data.csv', index = False)\n",
    "\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Acquire the Open Power Systems Data for Germany, which has been rapidly expanding its renewable energy production in recent years. The data set includes country-wide totals of electricity consumption, wind power production, and solar power production for 2006-2017. You can get the data here: https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opsd_germany_daily():\n",
    "    \"\"\"\n",
    "    This function uses or creates the \n",
    "    opsd_germany_daily csv and returns a df.\n",
    "    \"\"\"\n",
    "    if os.path.isfile('opsd_germany_daily.csv'):\n",
    "        df = pd.read_csv('opsd_germany_daily.csv', index_col=0)\n",
    "    else:\n",
    "        url = 'https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv'\n",
    "        df = pd.read_csv(url)\n",
    "        df.to_csv('opsd_germany_daily.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Make sure all the work that you have done above is reproducible. That is, you should put the code above into separate functions in the acquire.py file and be able to re-run the functions and get the same data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
